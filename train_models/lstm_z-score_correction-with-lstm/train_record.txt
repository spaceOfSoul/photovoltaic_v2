
###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 03:55:54.762210

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404361


###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 08:43:58.535118

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404361

Epoch [1/2000], Trn Loss: 674.1266, Val Loss: 570.9480 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 08:56:14.546481

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404361

Epoch [1/2000], Trn Loss: 676.5184, Val Loss: 573.1495 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:06:22.635341

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.


###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:07:01.817217

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 406026


###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:09:09.321076

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.


###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:10:02.249945

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.


###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:10:28.987853

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404490

Epoch [1/2000], Trn Loss: 658.8249, Val Loss: 536.6169 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:15:09.355390

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404490

Epoch [1/2000], Trn Loss: 670.6526, Val Loss: 548.4329 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:17:36.458135

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404490

Epoch [1/2000], Trn Loss: 674.9247, Val Loss: 551.1082 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:20:22.000728

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 2000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404490

Epoch [1/2000], Trn Loss: 682.3784, Val Loss: 555.9573 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:27:22.543557

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 1000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404490

Epoch [1/1000], Trn Loss: 673.5145, Val Loss: 549.1705 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:28:40.365264

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 1000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404490

Epoch [1/1000], Trn Loss: 677.5601, Val Loss: 552.9088 [(kW/hour)^2]

###################################################################
###################################################################
###################################################################

Current time: 2023-09-26 09:33:07.427753

--------------------Hyperparameters--------------------

model: {'seqLeng': 60, 'input_dim': 8, 'output_dim': 1, 'in_moving_mean': False, 'decomp_kernel': [3, 6, 12], 'feature_wise_norm': False, 'nHidden': 128, 'rec_dropout': 0, 'num_layers': 2, 'activ': 'relu', 'cnn_dropout': 0, 'kernel_size': [3, 3], 'padding': [1, 1], 'stride': [1, 1], 'nb_filters': [16, 32], 'pooling': [1, 1], 'dropout': 0, 'previous_steps': 5}

learning: {'nBatch': 14, 'lr': 0.001, 'max_epoch': 1000}

plot_corr: False

loss_plot_flag: True

save_losses: True

save_result: True

Model name: correction_LSTM


--------------------Training Mode (Training and Validating)--------------------
Training on the interval from 20220101 to 20221231.
Validating on the interval from 20220201 to 20221231.

The number of parameter in model : 404490

Epoch [1/1000], Trn Loss: 678.7650, Val Loss: 552.0979 [(kW/hour)^2]
Epoch [2/1000], Trn Loss: 649.8569, Val Loss: 527.3607 [(kW/hour)^2]
Epoch [3/1000], Trn Loss: 621.7798, Val Loss: 502.6883 [(kW/hour)^2]
Epoch [4/1000], Trn Loss: 593.6339, Val Loss: 477.4974 [(kW/hour)^2]
Epoch [5/1000], Trn Loss: 564.7405, Val Loss: 451.3488 [(kW/hour)^2]
Epoch [6/1000], Trn Loss: 534.5529, Val Loss: 424.0058 [(kW/hour)^2]
Epoch [7/1000], Trn Loss: 502.7061, Val Loss: 395.6460 [(kW/hour)^2]
Epoch [8/1000], Trn Loss: 469.2175, Val Loss: 367.4712 [(kW/hour)^2]
Epoch [9/1000], Trn Loss: 435.0816, Val Loss: 343.2216 [(kW/hour)^2]
Epoch [10/1000], Trn Loss: 403.7780, Val Loss: 332.2701 [(kW/hour)^2]
Epoch [11/1000], Trn Loss: 384.4521, Val Loss: 342.7605 [(kW/hour)^2]
Epoch [12/1000], Trn Loss: 386.1927, Val Loss: 348.5749 [(kW/hour)^2]
Epoch [13/1000], Trn Loss: 386.0192, Val Loss: 336.3244 [(kW/hour)^2]
Epoch [14/1000], Trn Loss: 370.8919, Val Loss: 316.0138 [(kW/hour)^2]
Epoch [15/1000], Trn Loss: 349.7950, Val Loss: 297.9084 [(kW/hour)^2]
Epoch [16/1000], Trn Loss: 331.9347, Val Loss: 285.5351 [(kW/hour)^2]
Epoch [17/1000], Trn Loss: 320.0034, Val Loss: 277.7862 [(kW/hour)^2]
Epoch [18/1000], Trn Loss: 312.3537, Val Loss: 272.3643 [(kW/hour)^2]
Epoch [19/1000], Trn Loss: 306.3958, Val Loss: 267.4268 [(kW/hour)^2]
Epoch [20/1000], Trn Loss: 300.1402, Val Loss: 261.8476 [(kW/hour)^2]
Epoch [21/1000], Trn Loss: 292.3740, Val Loss: 255.0466 [(kW/hour)^2]
Epoch [22/1000], Trn Loss: 282.4416, Val Loss: 246.8168 [(kW/hour)^2]
Epoch [23/1000], Trn Loss: 270.0459, Val Loss: 237.2369 [(kW/hour)^2]
Epoch [24/1000], Trn Loss: 255.1563, Val Loss: 226.6709 [(kW/hour)^2]
Epoch [25/1000], Trn Loss: 238.0120, Val Loss: 215.8310 [(kW/hour)^2]
Epoch [26/1000], Trn Loss: 219.2158, Val Loss: 205.8249 [(kW/hour)^2]
Epoch [27/1000], Trn Loss: 199.8527, Val Loss: 197.9110 [(kW/hour)^2]
Epoch [28/1000], Trn Loss: 181.3892, Val Loss: 192.6351 [(kW/hour)^2]
Epoch [29/1000], Trn Loss: 164.9806, Val Loss: 189.3214 [(kW/hour)^2]
Epoch [30/1000], Trn Loss: 150.9449, Val Loss: 188.1548 [(kW/hour)^2]
Epoch [31/1000], Trn Loss: 140.4538, Val Loss: 192.6712 [(kW/hour)^2]
Epoch [32/1000], Trn Loss: 137.4813, Val Loss: 205.3560 [(kW/hour)^2]
Epoch [33/1000], Trn Loss: 144.0949, Val Loss: 220.3568 [(kW/hour)^2]
Epoch [34/1000], Trn Loss: 153.5414, Val Loss: 230.7282 [(kW/hour)^2]
Epoch [35/1000], Trn Loss: 158.8117, Val Loss: 235.4845 [(kW/hour)^2]
Epoch [36/1000], Trn Loss: 160.0077, Val Loss: 234.6490 [(kW/hour)^2]
Epoch [37/1000], Trn Loss: 158.6256, Val Loss: 227.1856 [(kW/hour)^2]
Epoch [38/1000], Trn Loss: 154.2899, Val Loss: 215.3108 [(kW/hour)^2]
Epoch [39/1000], Trn Loss: 148.3307, Val Loss: 203.7748 [(kW/hour)^2]
Epoch [40/1000], Trn Loss: 143.7975, Val Loss: 195.0133 [(kW/hour)^2]
Epoch [41/1000], Trn Loss: 141.6015, Val Loss: 188.8035 [(kW/hour)^2]
Epoch [42/1000], Trn Loss: 140.6873, Val Loss: 184.5494 [(kW/hour)^2]
Epoch [43/1000], Trn Loss: 140.3462, Val Loss: 181.8590 [(kW/hour)^2]
Epoch [44/1000], Trn Loss: 140.5128, Val Loss: 179.8793 [(kW/hour)^2]
Epoch [45/1000], Trn Loss: 140.7678, Val Loss: 177.6882 [(kW/hour)^2]
Epoch [46/1000], Trn Loss: 140.4567, Val Loss: 175.2330 [(kW/hour)^2]
Epoch [47/1000], Trn Loss: 139.5193, Val Loss: 173.0485 [(kW/hour)^2]
Epoch [48/1000], Trn Loss: 138.2879, Val Loss: 171.4569 [(kW/hour)^2]
Epoch [49/1000], Trn Loss: 136.8644, Val Loss: 170.5066 [(kW/hour)^2]
Epoch [50/1000], Trn Loss: 135.2298, Val Loss: 170.2999 [(kW/hour)^2]
Epoch [51/1000], Trn Loss: 133.6607, Val Loss: 170.8260 [(kW/hour)^2]
Epoch [52/1000], Trn Loss: 132.5279, Val Loss: 171.6268 [(kW/hour)^2]
Epoch [53/1000], Trn Loss: 131.8154, Val Loss: 172.2055 [(kW/hour)^2]
Epoch [54/1000], Trn Loss: 131.3156, Val Loss: 172.6221 [(kW/hour)^2]
Epoch [55/1000], Trn Loss: 131.0923, Val Loss: 173.1404 [(kW/hour)^2]
Epoch [56/1000], Trn Loss: 131.1973, Val Loss: 173.7019 [(kW/hour)^2]
Epoch [57/1000], Trn Loss: 131.3599, Val Loss: 174.1057 [(kW/hour)^2]
Epoch [58/1000], Trn Loss: 131.3492, Val Loss: 174.2000 [(kW/hour)^2]
Epoch [59/1000], Trn Loss: 131.1928, Val Loss: 173.7546 [(kW/hour)^2]
Epoch [60/1000], Trn Loss: 130.9127, Val Loss: 172.6001 [(kW/hour)^2]
Epoch [61/1000], Trn Loss: 130.4629, Val Loss: 170.9580 [(kW/hour)^2]
Epoch [62/1000], Trn Loss: 129.9468, Val Loss: 169.2937 [(kW/hour)^2]
Epoch [63/1000], Trn Loss: 129.5324, Val Loss: 167.9389 [(kW/hour)^2]
Epoch [64/1000], Trn Loss: 129.2470, Val Loss: 167.0209 [(kW/hour)^2]
Epoch [65/1000], Trn Loss: 129.0471, Val Loss: 166.5422 [(kW/hour)^2]
Epoch [66/1000], Trn Loss: 128.9337, Val Loss: 166.3814 [(kW/hour)^2]
Epoch [67/1000], Trn Loss: 128.8959, Val Loss: 166.3419 [(kW/hour)^2]
Epoch [68/1000], Trn Loss: 128.8574, Val Loss: 166.3149 [(kW/hour)^2]
Epoch [69/1000], Trn Loss: 128.7553, Val Loss: 166.3625 [(kW/hour)^2]
Epoch [70/1000], Trn Loss: 128.6024, Val Loss: 166.6180 [(kW/hour)^2]
Epoch [71/1000], Trn Loss: 128.4320, Val Loss: 167.1604 [(kW/hour)^2]
Epoch [72/1000], Trn Loss: 128.2533, Val Loss: 167.9839 [(kW/hour)^2]
Epoch [73/1000], Trn Loss: 128.0832, Val Loss: 168.9988 [(kW/hour)^2]
Epoch [74/1000], Trn Loss: 127.9635, Val Loss: 170.0294 [(kW/hour)^2]
Epoch [75/1000], Trn Loss: 127.9146, Val Loss: 170.8726 [(kW/hour)^2]
Epoch [76/1000], Trn Loss: 127.9112, Val Loss: 171.4176 [(kW/hour)^2]
Epoch [77/1000], Trn Loss: 127.9228, Val Loss: 171.6897 [(kW/hour)^2]
Epoch [78/1000], Trn Loss: 127.9381, Val Loss: 171.7717 [(kW/hour)^2]
Epoch [79/1000], Trn Loss: 127.9389, Val Loss: 171.7227 [(kW/hour)^2]
Epoch [80/1000], Trn Loss: 127.9005, Val Loss: 171.5565 [(kW/hour)^2]
Epoch [81/1000], Trn Loss: 127.8253, Val Loss: 171.2460 [(kW/hour)^2]
Epoch [82/1000], Trn Loss: 127.7379, Val Loss: 170.7507 [(kW/hour)^2]
Epoch [83/1000], Trn Loss: 127.6523, Val Loss: 170.0814 [(kW/hour)^2]
Epoch [84/1000], Trn Loss: 127.5730, Val Loss: 169.3370 [(kW/hour)^2]
Epoch [85/1000], Trn Loss: 127.5100, Val Loss: 168.6553 [(kW/hour)^2]
Epoch [86/1000], Trn Loss: 127.4671, Val Loss: 168.1367 [(kW/hour)^2]
Epoch [87/1000], Trn Loss: 127.4312, Val Loss: 167.8111 [(kW/hour)^2]
Epoch [88/1000], Trn Loss: 127.3898, Val Loss: 167.6430 [(kW/hour)^2]
Epoch [89/1000], Trn Loss: 127.3417, Val Loss: 167.5582 [(kW/hour)^2]
Epoch [90/1000], Trn Loss: 127.2864, Val Loss: 167.4931 [(kW/hour)^2]
Epoch [91/1000], Trn Loss: 127.2224, Val Loss: 167.4411 [(kW/hour)^2]
Epoch [92/1000], Trn Loss: 127.1558, Val Loss: 167.4407 [(kW/hour)^2]
Epoch [93/1000], Trn Loss: 127.0964, Val Loss: 167.5253 [(kW/hour)^2]
Epoch [94/1000], Trn Loss: 127.0459, Val Loss: 167.6830 [(kW/hour)^2]
Epoch [95/1000], Trn Loss: 127.0013, Val Loss: 167.8534 [(kW/hour)^2]
Epoch [96/1000], Trn Loss: 126.9620, Val Loss: 167.9526 [(kW/hour)^2]
Epoch [97/1000], Trn Loss: 126.9240, Val Loss: 167.9225 [(kW/hour)^2]
Epoch [98/1000], Trn Loss: 126.8806, Val Loss: 167.7714 [(kW/hour)^2]
Epoch [99/1000], Trn Loss: 126.8300, Val Loss: 167.5601 [(kW/hour)^2]
Epoch [100/1000], Trn Loss: 126.7749, Val Loss: 167.3518 [(kW/hour)^2]
Epoch [101/1000], Trn Loss: 126.7159, Val Loss: 167.1745 [(kW/hour)^2]
Epoch [102/1000], Trn Loss: 126.6552, Val Loss: 167.0170 [(kW/hour)^2]
Epoch [103/1000], Trn Loss: 126.5962, Val Loss: 166.8532 [(kW/hour)^2]
Epoch [104/1000], Trn Loss: 126.5396, Val Loss: 166.6799 [(kW/hour)^2]
Epoch [105/1000], Trn Loss: 126.4827, Val Loss: 166.5321 [(kW/hour)^2]
Epoch [106/1000], Trn Loss: 126.4252, Val Loss: 166.4570 [(kW/hour)^2]
Epoch [107/1000], Trn Loss: 126.3659, Val Loss: 166.4774 [(kW/hour)^2]
Epoch [108/1000], Trn Loss: 126.3031, Val Loss: 166.5740 [(kW/hour)^2]
Epoch [109/1000], Trn Loss: 126.2375, Val Loss: 166.6994 [(kW/hour)^2]
Epoch [110/1000], Trn Loss: 126.1708, Val Loss: 166.8083 [(kW/hour)^2]
Epoch [111/1000], Trn Loss: 126.1032, Val Loss: 166.8887 [(kW/hour)^2]
Epoch [112/1000], Trn Loss: 126.0357, Val Loss: 166.9566 [(kW/hour)^2]
Epoch [113/1000], Trn Loss: 125.9688, Val Loss: 167.0266 [(kW/hour)^2]
Epoch [114/1000], Trn Loss: 125.9012, Val Loss: 167.0879 [(kW/hour)^2]
Epoch [115/1000], Trn Loss: 125.8319, Val Loss: 167.1070 [(kW/hour)^2]
Epoch [116/1000], Trn Loss: 125.7606, Val Loss: 167.0553 [(kW/hour)^2]
Epoch [117/1000], Trn Loss: 125.6866, Val Loss: 166.9358 [(kW/hour)^2]
Epoch [118/1000], Trn Loss: 125.6099, Val Loss: 166.7831 [(kW/hour)^2]
Epoch [119/1000], Trn Loss: 125.5314, Val Loss: 166.6350 [(kW/hour)^2]
Epoch [120/1000], Trn Loss: 125.4511, Val Loss: 166.5042 [(kW/hour)^2]
Epoch [121/1000], Trn Loss: 125.3694, Val Loss: 166.3783 [(kW/hour)^2]
Epoch [122/1000], Trn Loss: 125.2863, Val Loss: 166.2423 [(kW/hour)^2]
Epoch [123/1000], Trn Loss: 125.2010, Val Loss: 166.1026 [(kW/hour)^2]
Epoch [124/1000], Trn Loss: 125.1134, Val Loss: 165.9847 [(kW/hour)^2]
Epoch [125/1000], Trn Loss: 125.0235, Val Loss: 165.9072 [(kW/hour)^2]
Epoch [126/1000], Trn Loss: 124.9308, Val Loss: 165.8611 [(kW/hour)^2]
Epoch [127/1000], Trn Loss: 124.8356, Val Loss: 165.8175 [(kW/hour)^2]
Epoch [128/1000], Trn Loss: 124.7381, Val Loss: 165.7540 [(kW/hour)^2]
Epoch [129/1000], Trn Loss: 124.6384, Val Loss: 165.6740 [(kW/hour)^2]
Epoch [130/1000], Trn Loss: 124.5364, Val Loss: 165.5941 [(kW/hour)^2]
Epoch [131/1000], Trn Loss: 124.4320, Val Loss: 165.5175 [(kW/hour)^2]
Epoch [132/1000], Trn Loss: 124.3248, Val Loss: 165.4254 [(kW/hour)^2]
Epoch [133/1000], Trn Loss: 124.2145, Val Loss: 165.2992 [(kW/hour)^2]
Epoch [134/1000], Trn Loss: 124.1013, Val Loss: 165.1445 [(kW/hour)^2]
Epoch [135/1000], Trn Loss: 123.9849, Val Loss: 164.9869 [(kW/hour)^2]
Epoch [136/1000], Trn Loss: 123.8654, Val Loss: 164.8428 [(kW/hour)^2]
Epoch [137/1000], Trn Loss: 123.7429, Val Loss: 164.7034 [(kW/hour)^2]
Epoch [138/1000], Trn Loss: 123.6173, Val Loss: 164.5546 [(kW/hour)^2]
Epoch [139/1000], Trn Loss: 123.4887, Val Loss: 164.4034 [(kW/hour)^2]
Epoch [140/1000], Trn Loss: 123.3569, Val Loss: 164.2719 [(kW/hour)^2]
Epoch [141/1000], Trn Loss: 123.2217, Val Loss: 164.1652 [(kW/hour)^2]
Epoch [142/1000], Trn Loss: 123.0836, Val Loss: 164.0625 [(kW/hour)^2]
Epoch [143/1000], Trn Loss: 122.9423, Val Loss: 163.9476 [(kW/hour)^2]
Epoch [144/1000], Trn Loss: 122.7982, Val Loss: 163.8309 [(kW/hour)^2]
Epoch [145/1000], Trn Loss: 122.6514, Val Loss: 163.7254 [(kW/hour)^2]
Epoch [146/1000], Trn Loss: 122.5024, Val Loss: 163.6153 [(kW/hour)^2]
Epoch [147/1000], Trn Loss: 122.3513, Val Loss: 163.4795 [(kW/hour)^2]
Epoch [148/1000], Trn Loss: 122.1987, Val Loss: 163.3286 [(kW/hour)^2]
Epoch [149/1000], Trn Loss: 122.0449, Val Loss: 163.1838 [(kW/hour)^2]
Epoch [150/1000], Trn Loss: 121.8909, Val Loss: 163.0335 [(kW/hour)^2]
Epoch [151/1000], Trn Loss: 121.7374, Val Loss: 162.8639 [(kW/hour)^2]
Epoch [152/1000], Trn Loss: 121.5854, Val Loss: 162.7006 [(kW/hour)^2]
Epoch [153/1000], Trn Loss: 121.4360, Val Loss: 162.5589 [(kW/hour)^2]
Epoch [154/1000], Trn Loss: 121.2906, Val Loss: 162.4148 [(kW/hour)^2]
Epoch [155/1000], Trn Loss: 121.1502, Val Loss: 162.2804 [(kW/hour)^2]
Epoch [156/1000], Trn Loss: 121.0163, Val Loss: 162.1817 [(kW/hour)^2]
Epoch [157/1000], Trn Loss: 120.8901, Val Loss: 162.0859 [(kW/hour)^2]
Epoch [158/1000], Trn Loss: 120.7723, Val Loss: 162.0073 [(kW/hour)^2]
Epoch [159/1000], Trn Loss: 120.6637, Val Loss: 161.9619 [(kW/hour)^2]
Epoch [160/1000], Trn Loss: 120.5644, Val Loss: 161.9037 [(kW/hour)^2]
Epoch [161/1000], Trn Loss: 120.4731, Val Loss: 161.8902 [(kW/hour)^2]
Epoch [162/1000], Trn Loss: 120.3887, Val Loss: 161.8454 [(kW/hour)^2]
Epoch [163/1000], Trn Loss: 120.3082, Val Loss: 161.8628 [(kW/hour)^2]
Epoch [164/1000], Trn Loss: 120.2291, Val Loss: 161.7864 [(kW/hour)^2]
Epoch [165/1000], Trn Loss: 120.1488, Val Loss: 161.9023 [(kW/hour)^2]
Epoch [166/1000], Trn Loss: 120.0660, Val Loss: 161.5955 [(kW/hour)^2]
Epoch [167/1000], Trn Loss: 119.9852, Val Loss: 162.3170 [(kW/hour)^2]
Epoch [168/1000], Trn Loss: 119.9406, Val Loss: 160.8540 [(kW/hour)^2]
Epoch [169/1000], Trn Loss: 120.1238, Val Loss: 164.9745 [(kW/hour)^2]
Epoch [170/1000], Trn Loss: 120.8359, Val Loss: 160.5490 [(kW/hour)^2]
Epoch [171/1000], Trn Loss: 121.9575, Val Loss: 162.3864 [(kW/hour)^2]
Epoch [172/1000], Trn Loss: 119.6295, Val Loss: 165.0034 [(kW/hour)^2]
Epoch [173/1000], Trn Loss: 120.6701, Val Loss: 160.0909 [(kW/hour)^2]
Epoch [174/1000], Trn Loss: 121.3664, Val Loss: 160.4806 [(kW/hour)^2]
Epoch [175/1000], Trn Loss: 119.4578, Val Loss: 167.0464 [(kW/hour)^2]
Epoch [176/1000], Trn Loss: 121.7566, Val Loss: 159.7929 [(kW/hour)^2]
Epoch [177/1000], Trn Loss: 119.8209, Val Loss: 159.5431 [(kW/hour)^2]
Epoch [178/1000], Trn Loss: 120.4509, Val Loss: 163.2713 [(kW/hour)^2]
Epoch [179/1000], Trn Loss: 119.6858, Val Loss: 163.1989 [(kW/hour)^2]
Epoch [180/1000], Trn Loss: 119.6283, Val Loss: 159.3606 [(kW/hour)^2]
Epoch [181/1000], Trn Loss: 119.7875, Val Loss: 159.4722 [(kW/hour)^2]
Epoch [182/1000], Trn Loss: 119.3589, Val Loss: 163.3036 [(kW/hour)^2]
Epoch [183/1000], Trn Loss: 119.5924, Val Loss: 161.5163 [(kW/hour)^2]
Epoch [184/1000], Trn Loss: 118.9272, Val Loss: 159.0271 [(kW/hour)^2]
Epoch [185/1000], Trn Loss: 119.3773, Val Loss: 159.4294 [(kW/hour)^2]
Epoch [186/1000], Trn Loss: 118.7985, Val Loss: 162.4816 [(kW/hour)^2]
Epoch [187/1000], Trn Loss: 119.2115, Val Loss: 160.2879 [(kW/hour)^2]
Epoch [188/1000], Trn Loss: 118.5547, Val Loss: 158.5500 [(kW/hour)^2]
Epoch [189/1000], Trn Loss: 118.9641, Val Loss: 159.2886 [(kW/hour)^2]
Epoch [190/1000], Trn Loss: 118.4267, Val Loss: 161.5265 [(kW/hour)^2]
Epoch [191/1000], Trn Loss: 118.8098, Val Loss: 159.2362 [(kW/hour)^2]
Epoch [192/1000], Trn Loss: 118.2830, Val Loss: 158.2007 [(kW/hour)^2]
Epoch [193/1000], Trn Loss: 118.5644, Val Loss: 159.4239 [(kW/hour)^2]
Epoch [194/1000], Trn Loss: 118.1616, Val Loss: 160.6559 [(kW/hour)^2]
Epoch [195/1000], Trn Loss: 118.3746, Val Loss: 158.5226 [(kW/hour)^2]
Epoch [196/1000], Trn Loss: 118.0920, Val Loss: 158.1961 [(kW/hour)^2]
Epoch [197/1000], Trn Loss: 118.1388, Val Loss: 159.8454 [(kW/hour)^2]
Epoch [198/1000], Trn Loss: 118.0016, Val Loss: 159.6675 [(kW/hour)^2]
Epoch [199/1000], Trn Loss: 117.9102, Val Loss: 158.1256 [(kW/hour)^2]
Epoch [200/1000], Trn Loss: 117.9234, Val Loss: 158.5494 [(kW/hour)^2]
Epoch [201/1000], Trn Loss: 117.7294, Val Loss: 159.9671 [(kW/hour)^2]
Epoch [202/1000], Trn Loss: 117.8186, Val Loss: 158.6313 [(kW/hour)^2]
Epoch [203/1000], Trn Loss: 117.5909, Val Loss: 158.0588 [(kW/hour)^2]
Epoch [204/1000], Trn Loss: 117.6409, Val Loss: 159.2213 [(kW/hour)^2]
Epoch [205/1000], Trn Loss: 117.5023, Val Loss: 159.2634 [(kW/hour)^2]
Epoch [206/1000], Trn Loss: 117.4521, Val Loss: 158.0818 [(kW/hour)^2]
Epoch [207/1000], Trn Loss: 117.4293, Val Loss: 158.5306 [(kW/hour)^2]
Epoch [208/1000], Trn Loss: 117.2915, Val Loss: 159.4620 [(kW/hour)^2]
Epoch [209/1000], Trn Loss: 117.3194, Val Loss: 158.3480 [(kW/hour)^2]
Epoch [210/1000], Trn Loss: 117.1887, Val Loss: 158.1974 [(kW/hour)^2]
Epoch [211/1000], Trn Loss: 117.1513, Val Loss: 159.2121 [(kW/hour)^2]
Epoch [212/1000], Trn Loss: 117.1103, Val Loss: 158.6147 [(kW/hour)^2]
Epoch [213/1000], Trn Loss: 116.9988, Val Loss: 158.0453 [(kW/hour)^2]
Epoch [214/1000], Trn Loss: 116.9899, Val Loss: 158.7907 [(kW/hour)^2]
Epoch [215/1000], Trn Loss: 116.8990, Val Loss: 158.7128 [(kW/hour)^2]
Epoch [216/1000], Trn Loss: 116.8397, Val Loss: 157.9381 [(kW/hour)^2]
Epoch [217/1000], Trn Loss: 116.8074, Val Loss: 158.3891 [(kW/hour)^2]
Epoch [218/1000], Trn Loss: 116.7141, Val Loss: 158.6367 [(kW/hour)^2]
Epoch [219/1000], Trn Loss: 116.6795, Val Loss: 157.8347 [(kW/hour)^2]
Epoch [220/1000], Trn Loss: 116.6231, Val Loss: 158.0733 [(kW/hour)^2]
Epoch [221/1000], Trn Loss: 116.5435, Val Loss: 158.4612 [(kW/hour)^2]
Epoch [222/1000], Trn Loss: 116.5114, Val Loss: 157.7169 [(kW/hour)^2]
Epoch [223/1000], Trn Loss: 116.4452, Val Loss: 157.8303 [(kW/hour)^2]
Epoch [224/1000], Trn Loss: 116.3768, Val Loss: 158.2368 [(kW/hour)^2]
Epoch [225/1000], Trn Loss: 116.3409, Val Loss: 157.5604 [(kW/hour)^2]
Epoch [226/1000], Trn Loss: 116.2743, Val Loss: 157.6241 [(kW/hour)^2]
Epoch [227/1000], Trn Loss: 116.2112, Val Loss: 157.9858 [(kW/hour)^2]
Epoch [228/1000], Trn Loss: 116.1719, Val Loss: 157.3636 [(kW/hour)^2]
Epoch [229/1000], Trn Loss: 116.1093, Val Loss: 157.4454 [(kW/hour)^2]
Epoch [230/1000], Trn Loss: 116.0476, Val Loss: 157.7315 [(kW/hour)^2]
Epoch [231/1000], Trn Loss: 116.0060, Val Loss: 157.1572 [(kW/hour)^2]
Epoch [232/1000], Trn Loss: 115.9492, Val Loss: 157.3095 [(kW/hour)^2]
Epoch [233/1000], Trn Loss: 115.8875, Val Loss: 157.4893 [(kW/hour)^2]
Epoch [234/1000], Trn Loss: 115.8432, Val Loss: 156.9731 [(kW/hour)^2]
Epoch [235/1000], Trn Loss: 115.7926, Val Loss: 157.2178 [(kW/hour)^2]
Epoch [236/1000], Trn Loss: 115.7320, Val Loss: 157.2458 [(kW/hour)^2]
Epoch [237/1000], Trn Loss: 115.6833, Val Loss: 156.8255 [(kW/hour)^2]
Epoch [238/1000], Trn Loss: 115.6377, Val Loss: 157.1410 [(kW/hour)^2]
Epoch [239/1000], Trn Loss: 115.5816, Val Loss: 156.9799 [(kW/hour)^2]
Epoch [240/1000], Trn Loss: 115.5283, Val Loss: 156.7283 [(kW/hour)^2]
Epoch [241/1000], Trn Loss: 115.4832, Val Loss: 157.0353 [(kW/hour)^2]
Epoch [242/1000], Trn Loss: 115.4345, Val Loss: 156.7088 [(kW/hour)^2]
Epoch [243/1000], Trn Loss: 115.3811, Val Loss: 156.6987 [(kW/hour)^2]
Epoch [244/1000], Trn Loss: 115.3315, Val Loss: 156.8557 [(kW/hour)^2]
Epoch [245/1000], Trn Loss: 115.2864, Val Loss: 156.4996 [(kW/hour)^2]
Epoch [246/1000], Trn Loss: 115.2392, Val Loss: 156.7074 [(kW/hour)^2]
Epoch [247/1000], Trn Loss: 115.1887, Val Loss: 156.5875 [(kW/hour)^2]
Epoch [248/1000], Trn Loss: 115.1403, Val Loss: 156.4242 [(kW/hour)^2]
Epoch [249/1000], Trn Loss: 115.0954, Val Loss: 156.6322 [(kW/hour)^2]
Epoch [250/1000], Trn Loss: 115.0506, Val Loss: 156.3204 [(kW/hour)^2]
Epoch [251/1000], Trn Loss: 115.0038, Val Loss: 156.4594 [(kW/hour)^2]
Epoch [252/1000], Trn Loss: 114.9564, Val Loss: 156.3707 [(kW/hour)^2]
Epoch [253/1000], Trn Loss: 114.9106, Val Loss: 156.2297 [(kW/hour)^2]
Epoch [254/1000], Trn Loss: 114.8670, Val Loss: 156.3877 [(kW/hour)^2]
Epoch [255/1000], Trn Loss: 114.8237, Val Loss: 156.1026 [(kW/hour)^2]
Epoch [256/1000], Trn Loss: 114.7801, Val Loss: 156.2874 [(kW/hour)^2]
Epoch [257/1000], Trn Loss: 114.7356, Val Loss: 156.0786 [(kW/hour)^2]
Epoch [258/1000], Trn Loss: 114.6914, Val Loss: 156.1226 [(kW/hour)^2]
Epoch [259/1000], Trn Loss: 114.6480, Val Loss: 156.0859 [(kW/hour)^2]
Epoch [260/1000], Trn Loss: 114.6054, Val Loss: 155.9637 [(kW/hour)^2]
Epoch [261/1000], Trn Loss: 114.5637, Val Loss: 156.0740 [(kW/hour)^2]
Epoch [262/1000], Trn Loss: 114.5226, Val Loss: 155.8323 [(kW/hour)^2]
Epoch [263/1000], Trn Loss: 114.4818, Val Loss: 156.0395 [(kW/hour)^2]
Epoch [264/1000], Trn Loss: 114.4415, Val Loss: 155.7125 [(kW/hour)^2]
Epoch [265/1000], Trn Loss: 114.4017, Val Loss: 156.0101 [(kW/hour)^2]
Epoch [266/1000], Trn Loss: 114.3623, Val Loss: 155.5732 [(kW/hour)^2]
Epoch [267/1000], Trn Loss: 114.3247, Val Loss: 156.0328 [(kW/hour)^2]
Epoch [268/1000], Trn Loss: 114.2889, Val Loss: 155.3644 [(kW/hour)^2]
Epoch [269/1000], Trn Loss: 114.2583, Val Loss: 156.2000 [(kW/hour)^2]
Epoch [270/1000], Trn Loss: 114.2359, Val Loss: 154.9943 [(kW/hour)^2]
Epoch [271/1000], Trn Loss: 114.2384, Val Loss: 156.7575 [(kW/hour)^2]
Epoch [272/1000], Trn Loss: 114.2788, Val Loss: 154.3486 [(kW/hour)^2]
Epoch [273/1000], Trn Loss: 114.4588, Val Loss: 158.3149 [(kW/hour)^2]
Epoch [274/1000], Trn Loss: 114.7466, Val Loss: 153.7504 [(kW/hour)^2]
Epoch [275/1000], Trn Loss: 115.6325, Val Loss: 160.3116 [(kW/hour)^2]
Epoch [276/1000], Trn Loss: 115.6449, Val Loss: 153.6815 [(kW/hour)^2]
Epoch [277/1000], Trn Loss: 115.9998, Val Loss: 157.5111 [(kW/hour)^2]
Epoch [278/1000], Trn Loss: 114.3496, Val Loss: 156.1307 [(kW/hour)^2]
Epoch [279/1000], Trn Loss: 113.9471, Val Loss: 153.9205 [(kW/hour)^2]
Epoch [280/1000], Trn Loss: 114.7187, Val Loss: 158.7487 [(kW/hour)^2]
Epoch [281/1000], Trn Loss: 114.6888, Val Loss: 154.3456 [(kW/hour)^2]
Epoch [282/1000], Trn Loss: 114.1866, Val Loss: 155.4196 [(kW/hour)^2]
Epoch [283/1000], Trn Loss: 113.7764, Val Loss: 157.6824 [(kW/hour)^2]
Epoch [284/1000], Trn Loss: 114.1866, Val Loss: 153.8714 [(kW/hour)^2]
Epoch [285/1000], Trn Loss: 114.5340, Val Loss: 156.5656 [(kW/hour)^2]
Epoch [286/1000], Trn Loss: 113.8494, Val Loss: 155.9647 [(kW/hour)^2]
Epoch [287/1000], Trn Loss: 113.7172, Val Loss: 153.7229 [(kW/hour)^2]
Epoch [288/1000], Trn Loss: 114.1289, Val Loss: 156.8463 [(kW/hour)^2]
Epoch [289/1000], Trn Loss: 113.9277, Val Loss: 154.5023 [(kW/hour)^2]
Epoch [290/1000], Trn Loss: 113.5846, Val Loss: 154.2159 [(kW/hour)^2]
Epoch [291/1000], Trn Loss: 113.6066, Val Loss: 156.5273 [(kW/hour)^2]
Epoch [292/1000], Trn Loss: 113.7807, Val Loss: 153.7487 [(kW/hour)^2]
Epoch [293/1000], Trn Loss: 113.7211, Val Loss: 155.1804 [(kW/hour)^2]
Epoch [294/1000], Trn Loss: 113.4522, Val Loss: 155.5072 [(kW/hour)^2]
Epoch [295/1000], Trn Loss: 113.4748, Val Loss: 153.6073 [(kW/hour)^2]
Epoch [296/1000], Trn Loss: 113.6309, Val Loss: 155.8274 [(kW/hour)^2]
Epoch [297/1000], Trn Loss: 113.5039, Val Loss: 154.2902 [(kW/hour)^2]
Epoch [298/1000], Trn Loss: 113.3289, Val Loss: 154.1280 [(kW/hour)^2]
Epoch [299/1000], Trn Loss: 113.3195, Val Loss: 155.6914 [(kW/hour)^2]
Epoch [300/1000], Trn Loss: 113.3936, Val Loss: 153.7571 [(kW/hour)^2]
Epoch [301/1000], Trn Loss: 113.3724, Val Loss: 155.1463 [(kW/hour)^2]
Epoch [302/1000], Trn Loss: 113.2281, Val Loss: 154.9222 [(kW/hour)^2]
Epoch [303/1000], Trn Loss: 113.1752, Val Loss: 154.0389 [(kW/hour)^2]
Epoch [304/1000], Trn Loss: 113.2212, Val Loss: 155.6574 [(kW/hour)^2]
Epoch [305/1000], Trn Loss: 113.2138, Val Loss: 154.1647 [(kW/hour)^2]
Epoch [306/1000], Trn Loss: 113.1358, Val Loss: 154.8092 [(kW/hour)^2]
Epoch [307/1000], Trn Loss: 113.0562, Val Loss: 155.1047 [(kW/hour)^2]
Epoch [308/1000], Trn Loss: 113.0497, Val Loss: 154.0421 [(kW/hour)^2]
Epoch [309/1000], Trn Loss: 113.0698, Val Loss: 155.3752 [(kW/hour)^2]
Epoch [310/1000], Trn Loss: 113.0344, Val Loss: 154.2669 [(kW/hour)^2]
Epoch [311/1000], Trn Loss: 112.9677, Val Loss: 154.6547 [(kW/hour)^2]
Epoch [312/1000], Trn Loss: 112.9163, Val Loss: 154.9771 [(kW/hour)^2]
Epoch [313/1000], Trn Loss: 112.9057, Val Loss: 154.0745 [(kW/hour)^2]
Epoch [314/1000], Trn Loss: 112.9069, Val Loss: 155.1541 [(kW/hour)^2]
Epoch [315/1000], Trn Loss: 112.8792, Val Loss: 154.1176 [(kW/hour)^2]
Epoch [316/1000], Trn Loss: 112.8313, Val Loss: 154.6103 [(kW/hour)^2]
Epoch [317/1000], Trn Loss: 112.7828, Val Loss: 154.5344 [(kW/hour)^2]
Epoch [318/1000], Trn Loss: 112.7546, Val Loss: 154.0389 [(kW/hour)^2]
Epoch [319/1000], Trn Loss: 112.7425, Val Loss: 154.8130 [(kW/hour)^2]
Epoch [320/1000], Trn Loss: 112.7285, Val Loss: 153.8662 [(kW/hour)^2]
Epoch [321/1000], Trn Loss: 112.7039, Val Loss: 154.6756 [(kW/hour)^2]
Epoch [322/1000], Trn Loss: 112.6655, Val Loss: 154.0397 [(kW/hour)^2]
Epoch [323/1000], Trn Loss: 112.6262, Val Loss: 154.2902 [(kW/hour)^2]
Epoch [324/1000], Trn Loss: 112.5925, Val Loss: 154.3229 [(kW/hour)^2]
Epoch [325/1000], Trn Loss: 112.5675, Val Loss: 153.9415 [(kW/hour)^2]
Epoch [326/1000], Trn Loss: 112.5482, Val Loss: 154.5023 [(kW/hour)^2]
Epoch [327/1000], Trn Loss: 112.5293, Val Loss: 153.7646 [(kW/hour)^2]
Epoch [328/1000], Trn Loss: 112.5083, Val Loss: 154.5108 [(kW/hour)^2]
Epoch [329/1000], Trn Loss: 112.4820, Val Loss: 153.7511 [(kW/hour)^2]
Epoch [330/1000], Trn Loss: 112.4537, Val Loss: 154.3977 [(kW/hour)^2]
Epoch [331/1000], Trn Loss: 112.4226, Val Loss: 153.8227 [(kW/hour)^2]
Epoch [332/1000], Trn Loss: 112.3923, Val Loss: 154.2331 [(kW/hour)^2]
Epoch [333/1000], Trn Loss: 112.3624, Val Loss: 153.8981 [(kW/hour)^2]
Epoch [334/1000], Trn Loss: 112.3341, Val Loss: 154.0638 [(kW/hour)^2]
Epoch [335/1000], Trn Loss: 112.3070, Val Loss: 153.9426 [(kW/hour)^2]
Epoch [336/1000], Trn Loss: 112.2808, Val Loss: 153.9143 [(kW/hour)^2]
Epoch [337/1000], Trn Loss: 112.2553, Val Loss: 153.9698 [(kW/hour)^2]
Epoch [338/1000], Trn Loss: 112.2304, Val Loss: 153.7836 [(kW/hour)^2]
Epoch [339/1000], Trn Loss: 112.2059, Val Loss: 154.0119 [(kW/hour)^2]
Epoch [340/1000], Trn Loss: 112.1822, Val Loss: 153.6361 [(kW/hour)^2]
Epoch [341/1000], Trn Loss: 112.1601, Val Loss: 154.1153 [(kW/hour)^2]
Epoch [342/1000], Trn Loss: 112.1408, Val Loss: 153.4010 [(kW/hour)^2]
Epoch [343/1000], Trn Loss: 112.1283, Val Loss: 154.4009 [(kW/hour)^2]
Epoch [344/1000], Trn Loss: 112.1287, Val Loss: 152.9675 [(kW/hour)^2]
Epoch [345/1000], Trn Loss: 112.1673, Val Loss: 155.2320 [(kW/hour)^2]
Epoch [346/1000], Trn Loss: 112.2689, Val Loss: 152.2514 [(kW/hour)^2]
Epoch [347/1000], Trn Loss: 112.6019, Val Loss: 157.5786 [(kW/hour)^2]
Epoch [348/1000], Trn Loss: 113.1223, Val Loss: 151.9590 [(kW/hour)^2]
Epoch [349/1000], Trn Loss: 114.7155, Val Loss: 160.7430 [(kW/hour)^2]
Epoch [350/1000], Trn Loss: 114.7120, Val Loss: 152.1697 [(kW/hour)^2]
Epoch [351/1000], Trn Loss: 115.3855, Val Loss: 156.5066 [(kW/hour)^2]
Epoch [352/1000], Trn Loss: 112.5138, Val Loss: 155.3804 [(kW/hour)^2]
Epoch [353/1000], Trn Loss: 112.1139, Val Loss: 152.0973 [(kW/hour)^2]
